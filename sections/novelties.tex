One of the main observations in our baselines predictions was the patchy nature of classifications, as it did not produce coherent streets in most cases. When looking directly at the output probabilities, it was similar to a grey-scale image of the input. Thus the model was only focusing on texture instead of shape. Out novelties tried to remedy this by including inductive biases about shape in out classification.

\subsection{Deformations}

\subsection{Contrastive Learning in Bottleneck}

\subsection{UNET bottleneck}
\input{sections/novelties/bottleneck}

\subsection{Scrapped Novelties}
    This section gives an overview of the novelties that were tried, but didn't improve the model.

    Learned Ensemblers, Slime, Soft dice loss, GNN, CRF, Graph cuts. Soft dice loss (or maybe mention that in baseline)

    \subsubsection{GAN}
    \input{sections/novelties/gan}
